---
title: 'Build Workflows'
sidebarTitle: 'Build Workflows'
description: 'Find out how you can build your workflows in a few steps'
---

# üõ†Ô∏è How to Build Workflows

After successfully installing the `workflowcommon` Python SDK, it‚Äôs now time to build the workflow:

1. ‚û°Ô∏è¬†**Import nodes and builder**
2. ‚û°Ô∏è¬†**Create the workflow builder**
3. ‚û°Ô∏è¬†**Define and add nodes**
4. ‚û°Ô∏è¬†**Connect the nodes**
5. ‚è±Ô∏è¬†**Build and visualize the pipeline**
6. ‚è±Ô∏è¬†**Execute the pipeline**
7. ‚è±Ô∏è¬†**Get outputs and results**


## ‚úçÔ∏è Example 1: Get Text from a File ‚Üí Analyze with LLM ‚Üí Upload Result

1. ‚û°Ô∏è¬†**Import nodes and builder**
    
    ```python
    # Import workflow builder
    from workflowcommon.builder import FlowBuilder
    
    # Import nodes
    from workflowcommon.nodes import (
        S3LoadFile,
        LLM,
        S3UploadFile
    )
    ```
    
2. ‚û°Ô∏è¬†**Create the workflow builder**
    
    ```python
    # Create workflow builder
    builder = FlowBuilder()
    ```
    
3. ‚û°Ô∏è¬†**Define and add nodes**
    
    ```python
    # Load file from S3
    s3_loader = builder.add_node(
        S3LoadFile.Node(
            name="S3LoadFile",
            params=S3LoadFile.Params(
                output_field="file_content",
                user_id="user123",
                file_key="my_txt_file.txt",
                file_type="text",
            )
        )
    )
    
    # Analyze with LLM
    llm = builder.add_node(
        LLM.Node(
            name="LLM",
            params=LLM.Params(
                input_field="file_content.data",
                output_field="response",
                llm_provider="Mistral",  # or "OpenAI", "Anthropic"
            )
        )
    )
    
    # Upload result to S3
    s3_uploader = builder.add_node(
        S3UploadFile.Node(
            name="S3UploadFile",
            params=S3UploadFile.Params(
                input_field="response.content",
                user_id="user123",
                file_key="my_md_file.md",  # upload results to Markdown file
            )
        )
    )
    ```
    
4. ‚û°Ô∏è¬†**Connect the nodes**
    
    ```python
    # Connect the flow in the correct order
    s3_loader.connect_to(llm)
    llm.connect_to(s3_uploader)
    ```
    

## üìÑ Example 2: Load a PDF and Extract Text

1. ‚û°Ô∏è¬†**Import nodes and builder**
    
    ```python
    # Import workflow builder
    from workflowcommon.builder import FlowBuilder
    
    # Import nodes
    from workflowcommon.nodes import (
        S3LoadFile,
        ExtractTextPDF
    )
    ```
    
2. ‚û°Ô∏è¬†**Create the workflow builder**
    
    ```python
    # Create workflow builder
    builder = FlowBuilder()
    ```
    
3. ‚û°Ô∏è¬†**Define and add nodes**
    
    ```python
    # Load PDF file from S3
    s3_loader = builder.add_node(
        S3LoadFile.Node(
            params=S3LoadFile.Params(
                output_field="pdf_base64",
                user_id="user123",
                file_key="my_pdf_file.pdf",
                file_type="pdf"
            )
        )
    )
    
    # Extract text from PDF
    pdf_text_extractor = builder.add_node(
        ExtractTextPDF.Node(
            name="ExtractTextPDF",
            params=ExtractTextPDF.Params(
                input_field="pdf_base64",
                output_field="pdf_text"
            )
        )
    )
    ```
    
4. ‚û°Ô∏è¬†**Connect the nodes**
    
    ```python
    # Connect the flow in the correct order
    s3_loader.connect_to(pdf_text_extractor)
    ```

## üß† Tips for Designing Workflows

- **Use `.connect_to()`** to link nodes in the correct order
- **Specify `input_field` and `output_field`** to pass data between nodes (or not depending on node type)
- **Call `pipeline.execute()`** to run the pipeline **sequentially**
- **Use `display(pipeline)` in a notebook to see a visual graph**


## üîç More Ideas

Here are other workflows you can build with the SDK:

- Load and extract text from PDF ‚Üí Summarize with LLM ‚Üí Store summary in graph memory
- Generate Cypher queries from user prompts using `Text2Cypher` node
- Build a graph from extracted entities and write it into TuringDB
- Loop over a list of companies and fetch financial data using `ForEach` node

For a full list of supported nodes and their parameters, see the Node Reference.


Build fast, flexible, and intelligent workflows with **TuringDB + `workflowcommon`** to supercharge your data, AI, and graph analytics stack.